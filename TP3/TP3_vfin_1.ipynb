{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ac36abac-e9ce-4594-881a-96b2ad7ae2f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\rafael\\anaconda3\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from pandas) (2.1.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\rafael\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "#Instalo e importo paquetes \n",
    "!pip install pandas\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import os\n",
    "from IPython.display import Image, display, HTML\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.gridspec import GridSpec\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f1077e2-fa38-41c0-8f67-c8723c298c4e",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "\n",
    "<h3 style=\"color: navy;\">Parte I: Creación de variables, histogramas, kernels y resumen de la base de datos final</h3>\n",
    "<p> \n",
    "La idea de esta primera parte es que completen la limpieza de la base de datos que contiene las observaciones del primer trimestre de 2005 y del \n",
    "primer trimestre de 2025. La base final a trabajar resultante debe incluir todas las variables presentes en ambos trimestres, expresadas de manera \n",
    "homogénea. Es decir, si la variable CH04 en 2005 toma los valores “Hombre” o “Mujer”, y en 2025 toma los valores 1 y 2, la variable limpia \n",
    "en la base final debe tener solamente dos valores consistentes. \n",
    "</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33da4696-f4f6-4148-ae7b-fdfb04b4fc15",
   "metadata": {},
   "outputs": [],
   "source": [
    "## INDIVIDUOS  ##############\n",
    "\n",
    "#SUBO EL SET DE DATOS INDIVISUALES DEL PRIMER TRIMESTRE DE 2025\n",
    "t0125 = pd.read_excel('usu_individual_T125.xlsx')\n",
    "\n",
    "#SUBO EL SET DE DATOS INDIVISUALES DEL PRIMER TRIMESTRE DE 2005\n",
    "t0105 = pd.read_stata('Individual_t105.dta')\n",
    "\n",
    "############# HOGARES  ##############\n",
    "\n",
    "#SUBO EL SET DE DATOS HOGARES DEL PRIMER TRIMESTRE DE 2025\n",
    "th0125 = pd.read_excel('usu_hogar_T125.xlsx')\n",
    "#th0125\n",
    "\n",
    "#SUBO EL SET DE DATOS HOGARES DEL PRIMER TRIMESTRE DE 2005\n",
    "th0105 = pd.read_stata('Hogar_t105.dta')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c5a2409-67b3-4d4d-a14f-9f9a219a331e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CREO UNA FUNCION QUE ME TRANSFORME EL TIPO DE DATO DE LA COLUMNA EN CUESTION.\n",
    "#LE DEBO CARGAR EL NOMBRE DEL DATAFRAME, EL NOMBRE DE LA COLUMNA Y EL MAPEO DE DATOS QUE DEBE TRANSFORMAR\n",
    "\n",
    "def mapear_columna(df, columna, diccionario):\n",
    "    \n",
    "    #Creo esta lista para ir depositando los errores que vaya encontrado la transformacion y después ver qué corregir \n",
    "    errores = []\n",
    "\n",
    "    # Asegura que la columna esté en formato string para comparar\n",
    "    df[columna] = df[columna].astype(str)\n",
    "\n",
    "    #Armo un bucle para que recorra todas las celdas de la columna y vaya tranformando los datos segun el diccionario.\n",
    "    #Para ello utilizo la función .at[] con la que modifico una sola celda en un DataFrame, usando la combinación de índice y nombre de columna.\n",
    "    \n",
    "    for i in df.index:\n",
    "        valor = df.at[i, columna]\n",
    "        if valor in diccionario:\n",
    "            df.at[i, columna] = diccionario[valor]\n",
    "        else:\n",
    "            errores.append((i, valor))\n",
    "\n",
    "    # Convierte la columna al tipo int64 si todo salió bien\n",
    "    try:\n",
    "        df[columna] = df[columna].astype('int64')\n",
    "    except ValueError:\n",
    "        pass  # Si hay errores, no se puede convertir\n",
    "\n",
    "    return df, errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc4b48e-6ac6-42e2-b2cd-5e66a740c9b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# EMPIEZO A HOMOGENEIZAR LOS DATOS  ##############\n",
    "\n",
    "#region 2005\n",
    "mapa = {    'Gran Buenos Aires': 1,    'NOA':40,    'NEA':41,    'Cuyo':42,    'Pampeana':43,    'Patagónica':44 }\n",
    "t0105, errores = mapear_columna(t0105, 'region', mapa)\n",
    "\n",
    "\n",
    "#aglomerado 2005\n",
    "mapa = {'Gran La Plata': 2, 'Bahía Blanca - Cerri': 3,'Gran Rosario': 4,'Gran Santa Fe': 5,'Gran Paraná': 6,'Posadas': 7,\n",
    "        'Gran Resistencia': 8, 'Gran Mendoza': 10,'Corrientes': 12,'Gran Córdoba': 13,'Concordia': 14,'Formosa': 15,\n",
    "        'Cdro. Rivadavia – Rada Tilly': 9, 'Comodoro Rivadavia - Rada Tilly':9,\n",
    "        'Neuquén – Plottier': 17,'Neuquén - Plottier':17,\n",
    "        'S.del Estero - La Banda': 18,'Santiago del Estero - La Banda':18,\n",
    "        'Jujuy - Palpalá': 19,'Río Gallegos': 20,'Gran Catamarca': 22,'Salta': 23,'La Rioja': 25,\n",
    "        'San Luis - El Chorrillo': 26,'Gran San Juan': 27,'Gran Tucumán - T. Viejo': 29, 'Gran Tucumán - Tafí Viejo':29,\n",
    "        'Santa Rosa - Toay': 30, 'Ushuaia - Río Grande': 31,'Ciudad de Buenos Aires': 32,'Partidos del GBA': 33,\n",
    "        'Mar del Plata - Batán': 34,'Río Cuarto': 36\n",
    "}\n",
    "t0105, errores = mapear_columna(t0105, 'aglomerado', mapa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa7a5850-610a-4dba-813c-28d400c739aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ch3 2005\n",
    "mapa = {       'Jefe/a': 1,     'Jefe': 1,     'Cónyuge/pareja': 2,    'Cónyuge/Pareja': 2,    'Hijo/a/hijastro/a': 3,  'Hijo/Hijastro': 3,\n",
    "         'Yerno/nuera': 4,   'Yerno/Nuera': 4,    'Nieto/a': 5,            'Nieto': 5,         'Madre/padre': 6,         'Madre/Padre': 6,\n",
    "         'Suegro/a': 7,             'Suegro': 7, 'Hermano/a': 8,          'Hermano': 8,\n",
    "    'Otros familiares': 9,    'No familiares': 10\n",
    "}\n",
    "t0105, errores = mapear_columna(t0105, 'ch03', mapa)\n",
    "\n",
    "#ch04 2005 lo llevo a numerico dummies.. En 2025, retransformo como dummie llevando a mujer a 0 en lugar de 2\n",
    "mapa = {    'Varón': 1,    'Mujer': 0  }\n",
    "t0105, errores = mapear_columna(t0105, 'ch04', mapa)\n",
    "\n",
    "t0125['CH04'] = np.where(t0125['CH04']  ==  1,1,0)\n",
    "\n",
    "######################################################################\n",
    "#Para el 2005 - Llevo de 1 a 97 años para homogeneizar xq en 2005 a ese sector lo trataban con un texto\n",
    "t0105['ch06'] = t0105['ch06'].astype(str)\n",
    "\n",
    "t0105 = t0105.loc[\n",
    "    (t0105['ch06'] != 'Menos de 1 año') & \n",
    "    (t0105['ch06'] != '98 y más años')\n",
    "]\n",
    "\n",
    "t0105['ch06'] = pd.to_numeric(t0105['ch06'], errors='coerce')\n",
    "\n",
    "#############\n",
    "\n",
    "#Para el 2025\n",
    "t0125['CH06'] = t0125['CH06'].astype(str)\n",
    "\n",
    "t0125 = t0125.loc[\n",
    "    (t0125['CH06'] != 'Menos de 1 año') & \n",
    "    (t0125['CH06'] != '98 y más años') &\n",
    "    (t0125['CH06'] != '98') & (t0125['CH06'] != '99') & (t0125['CH06'] != '100') & (t0125['CH06'] != '101') & \n",
    "    (t0125['CH06'] != '102') & (t0125['CH06'] != '103') & \n",
    "    (t0125['CH06'] != '-1') \n",
    "]\n",
    "\n",
    "#una vez recodificado transformo el tipo de dato\n",
    "t0125['CH06'] = pd.to_numeric(t0125['CH06'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e1780af-c184-4327-ae8d-6f48c98b0359",
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################################################\n",
    "#CH07 - \n",
    "\n",
    "mapa = {    'Unido':1, 'Casado':2, 'Separado o divorciado':3, 'Viudo':4, 'Soltero':5,'Ns/Nr':0 }\n",
    "\n",
    "t0105, errores = mapear_columna(t0105, 'ch07', mapa)\n",
    "\n",
    "#Tambien haré Null los valores 0, 0.0 y los 99\n",
    "t0105['ch07'] = t0105['ch07'].replace(0, np.nan)\n",
    "t0105['ch07'] = t0105['ch07'].replace('0.0', np.nan)\n",
    "t0105['ch07'] = t0105['ch07'].replace(99, np.nan)\n",
    "\n",
    "#####################################################\n",
    "#CH08\n",
    "# Hay items escritos de maneras diferentes, pero como los diccionarios nos permites repetir valores pero No Keys, \n",
    "# repetimos el código tipificado con su key diferente\n",
    "\n",
    "mapa = {\n",
    "'Obra social (incluye PAMI)':1, 'Mutual/Prepaga/Servicio de emergencia':2, 'Planes y seguros públicos':3, 'No paga ni le descuentan':4, 'Ns./Nr.':9, \n",
    "'Obra social y mutual/prepaga/servicio de emergencia':12, 'Obra social y planes y seguros públicos':13, \n",
    "'Mutual /prepaga / servicio de emergencia / Planes y Seguros Públicos':23, \n",
    "'Mutual/prepaga/servicio de emergencia/planes y seguros públi':23,\n",
    "'Obra social, mutual/prepaga/servicio de emergencia y planes':123, \n",
    "'Obra social, mutual / prepaga / servicio de emergencia y Planes y Seguros Públicos':123\n",
    "}\n",
    "\n",
    "t0105, errores = mapear_columna(t0105, 'ch08', mapa)\n",
    "#####################################################\n",
    "\n",
    "#Para ch12\n",
    "# Se tomara como null los codigos no tipificados como el 0 o 99, el Ns/Nc, y el 0.0 que aparecen entre los registros.\n",
    "\n",
    "mapa = {'Jardín/Preescolar' : 1,\t'Jardín/preescolar' : 1, 'Primario' : 2, 'EGB' : 3, 'Secundario' : 4, 'Polimodal' : 5, \n",
    "        'Terciario' : 6, 'Universitario' : 7, 'Posgrado universitario' : 8, 'Posgrado Universitario' : 8, \n",
    "            'Educación especial (discapacidad)' : 9,  'Educación especial (discapacitado)':9, 'Ns./Nr.':0, 'Ns/Nr.':0, '99':0,'0.0':0\n",
    "           }\n",
    "\n",
    "t0105, errores = mapear_columna(t0105, 'ch12', mapa)\n",
    "\n",
    "t0105['ch12'] = t0105['ch12'].replace(0, np.nan)\n",
    "t0125['CH12'] = t0125['CH12'].replace(0, np.nan)\n",
    "\n",
    "\n",
    "##############################################################################################################################\n",
    "#Para ch13\n",
    "# acá existe tupificacion, recategorizo valores como 0 o 0.0 a \"no sabe/ no contesta\"\n",
    "mapa = {'Sí': 1, 'No':2, \n",
    "        'Ns/Nr':9, 'Ns./Nr.':9, '0':9, '0.0':9        }\n",
    "\n",
    "t0105, errores = mapear_columna(t0105, 'ch13', mapa)\n",
    "\n",
    "t0105['ch13'] = t0105['ch13'].replace(9, np.nan)\n",
    "t0125['CH13'] = t0125['CH13'].replace(9, np.nan)\n",
    "\n",
    "##############################################################################################################################\n",
    "#CH14\n",
    "\n",
    "#Primero lo llevo a string para despues llevarlo a numerico al campo del ultimo curso aprobado\n",
    "\n",
    "t0105['ch14'] = t0105['ch14'].astype(str).str.strip()\n",
    "t0105['ch14'] = pd.to_numeric(t0105['ch14'], errors='coerce')\n",
    "\n",
    "t0125['CH14'] = np.where(((t0125['CH14']  ==  98)|(t0125['CH14']  ==  99)|(t0125['CH14']  ==  '0.0')|(t0125['CH14']  ==  'Ns/Nr.')),np.nan,t0125['CH14'])\n",
    "t0105['ch14'] = np.where(((t0105['ch14']  ==  98)|(t0105['ch14']  ==  99)|(t0105['ch14']  ==  '0.0')|(t0105['ch14']  ==  'Ns/Nr.')),np.nan,t0105['ch14'])\n",
    "\n",
    "#reemplaza los valores nulos por el 0, que si esta tipificado aqui\n",
    "t0105['ch14'] = t0105['ch14'].fillna(0)\n",
    "\n",
    "# Hay un dato de un terciario que manifiesta 9 años en la ch14.. Lo reconsidero a 3 años \n",
    "\n",
    "t0125['CH14'] = np.where((t0125['CH14'] > 3) & (t0125['CH12'] == 6), 4, t0125['CH14'] )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0608aa-8220-46f1-8c57-2957b6496aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#nivel_ed\n",
    "\n",
    "\n",
    "#Para el Nivel educativo\n",
    "\n",
    "mapa = {'Primaria Completa':2, 'Primaria Incompleta (incluye educación especial)':1, 'Secundaria Completa':4, \n",
    "            'Secundaria Incompleta':3, 'Sin instrucción':7, 'Superior Universitaria Completa':6, \n",
    "            'Superior Universitaria Incompleta':5, 'Ns/Nr':9\n",
    "           }\n",
    "\n",
    "t0105, errores = mapear_columna(t0105, 'nivel_ed', mapa)\n",
    "\n",
    "#############################################################\n",
    "\n",
    "#estado\n",
    "\n",
    "mapa = {'Entrevista individual no realizada (no respuesta al cuestion':0, \n",
    "                'Ocupado':1, 'Desocupado':2, 'Inactivo':3, 'Menor de 10 años':4\n",
    "               }\n",
    "\n",
    "t0105, errores = mapear_columna(t0105, 'estado', mapa)\n",
    "\n",
    "#############################################################\n",
    "\n",
    "#Para cat_ocup - la categoria ocupacional\n",
    "\n",
    "mapa = {'Patrón':1, 'Cuenta propia':2, 'Obrero o empleado':3,\n",
    "              'Trabajador familiar sin remuneración':4,'Nr/Nr':9\n",
    "             }\n",
    "t0105, errores = mapear_columna(t0105, 'cat_ocup', mapa)\n",
    "\n",
    "t0105['cat_ocup'] = pd.to_numeric(t0105['cat_ocup'], errors='coerce')\n",
    "\n",
    "#############################################################\n",
    "\n",
    "#CAT_INAC\n",
    "\n",
    "cat_inac_map = {'Ama de casa':4, 'Discapacitado':6, 'Estudiante':3, 'Jubilado/pensionado':1, \n",
    "                'Menor de 6 años':5, 'Otros':7, 'Rentista':2\n",
    "               }\n",
    "t0105, errores = mapear_columna(t0105, 'cat_inac', cat_inac_map)\n",
    "\n",
    "t0105['cat_inac'] = pd.to_numeric(t0105['cat_inac'], errors='coerce')\n",
    "\n",
    "#############################################################\n",
    "\n",
    "#En p21 hay valores -9, pasaran a ser considerados como cero\n",
    "\n",
    "t0105['p21'] = t0105['p21'].replace(-9, np.nan)\n",
    "t0125['P21'] = t0125['P21'].replace(-9, np.nan)\n",
    "\n",
    "t0125['P21'] = t0125['P21'].fillna(0)\n",
    "\n",
    "#############################################################\n",
    "# Se termina de limpiar datos de ambas bases. \n",
    "\n",
    "#Como el valor \"0\" no esta tipificado dentro de los cuadros de referencia, lo reemplazare por un valor nulo\n",
    "\n",
    "t0105['cat_inac'] = t0105['cat_inac'].replace(0, np.nan)\n",
    "t0125['CAT_INAC'] = t0125['CAT_INAC'].replace(0, np.nan)\n",
    "\n",
    "t0105['cat_ocup'] = t0105['cat_ocup'].replace(0, np.nan)\n",
    "t0125['CAT_OCUP'] = t0125['CAT_OCUP'].replace(0, np.nan)\n",
    "\n",
    "#Ahora, a los Nulos de  CAT_OCUP los convierto en el codigo de Ns/Nc que si esta tipificado\n",
    "t0105['cat_ocup'] = t0105['cat_ocup'].fillna(9)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eac802d-47b6-49b8-a4d6-05c58bc8d69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#PP04B_COD\n",
    "\n",
    "\n",
    "t0105['pp04b_cod'] = pd.to_numeric(t0105['pp04b_cod'], errors='coerce')\n",
    "t0105['pp04b_cod'] = t0105['pp04b_cod'].replace(0, np.nan)\n",
    "\n",
    "#Porque sino despues no voy a poder concatenar los 2 Dataframes \n",
    "t0125['PP04B_COD'] = pd.to_numeric(t0125['PP04B_COD'], errors='coerce')\n",
    "\n",
    "##############################################################################################################################\n",
    "# PP3F_TOT y PP3E_TOT \n",
    "\n",
    "\n",
    "#Trasformo los valores mayores a 112hs (16hs diarios) semanales se los considerará nulos\n",
    "\n",
    "t0125['PP3E_TOT'] = np.where(t0125['PP3E_TOT'] >112,np.nan,t0125['PP3E_TOT'])\n",
    "t0105['pp3e_tot'] = np.where(t0105['pp3e_tot'] >112,np.nan,t0105['pp3e_tot'])\n",
    "\n",
    "t0125['PP3F_TOT'] = np.where(t0125['PP3F_TOT'] >112,np.nan,t0125['PP3F_TOT'])\n",
    "t0105['pp3f_tot'] = np.where(t0105['pp3f_tot'] >112,np.nan,t0105['pp3f_tot'])\n",
    "\n",
    "\n",
    "#TRANSFORMO LOS DATOS EN 0´s EN NULLs Y A LOS 999 EN 0\n",
    "\n",
    "t0125['PP3E_TOT'] = np.where(t0125['PP3E_TOT']  ==  999,np.nan,t0125['PP3E_TOT'])\n",
    "t0105['pp3e_tot'] = np.where(t0105['pp3e_tot']  ==  999,np.nan,t0105['pp3e_tot'])\n",
    "\n",
    "\n",
    "t0125['PP3F_TOT'] = np.where(t0125['PP3F_TOT']  ==  999,np.nan,t0125['PP3F_TOT'])\n",
    "t0105['pp3f_tot'] = np.where(t0105['pp3f_tot']  ==  999,np.nan,t0105['pp3f_tot'])\n",
    "\n",
    "\n",
    "t0105['pp3e_tot'] = t0105['pp3e_tot'].replace(0, np.nan)\n",
    "t0125['PP3E_TOT'] = t0125['PP3E_TOT'].replace(0, np.nan)\n",
    "\n",
    "##############################################################################################################################\n",
    "\n",
    "#AGREGO UNA COLUMNA EN CADA TRIMESTRE PARA INDICAR EL AÑO\n",
    "\n",
    "t0105['ANIO'] = np.int64(2005)\n",
    "t0125['ANIO'] = np.int64(2025)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b2fe73-3dc0-47d3-9e74-ac4faf1ed194",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#AHORA VOY ESTABLECER LAS COLUMNAS CON LAS QUE ME VOY A QUEDAR, EN LAS 2 TABLAS\n",
    "\n",
    "t0105_sel_c = t0105[[\n",
    "'CODUSU', 'nro_hogar', 'region', 'aglomerado', 'pondera', 'ch03', 'ch04', 'ch06', 'ch07', 'ch08', 'ch12', 'ch13', 'ch14', \n",
    "    'nivel_ed', 'estado', 'cat_ocup', 'cat_inac', 'pp3e_tot', 'pp3f_tot', 'pp04b_cod', 'p21', 'itf', 'ipcf', 'ANIO'\n",
    "]].copy()\n",
    "\n",
    "t0125_sel_c = t0125[[\n",
    "'CODUSU', 'NRO_HOGAR', 'REGION', 'AGLOMERADO', 'PONDERA', 'CH03', 'CH04', 'CH06', 'CH07', 'CH08', 'CH12', 'CH13', 'CH14', \n",
    "    'NIVEL_ED', 'ESTADO', 'CAT_OCUP', 'CAT_INAC', 'PP3E_TOT', 'PP3F_TOT', 'PP04B_COD', 'P21', 'ITF', 'IPCF', 'ANIO'\n",
    "]].copy()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e655edbe-02c7-4e12-a8a3-1989e50a243c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tengo que renombrar las columnas para que ambos dataframes tengan igual nombre porque sino \n",
    "#no voy a poder poder concatenar correctamente (en la misma columna, una abajo de la otra)los 2 DataFrames\n",
    "\n",
    "t0105_sel_c = t0105_sel_c.rename(columns={\n",
    "'nro_hogar': 'NRO_HOGAR',\n",
    "'region':'REGION',\n",
    "'aglomerado': 'AGLOMERADO',\n",
    "'pondera': 'PONDERA',\n",
    "'ch03': 'CH03',\n",
    "'ch04': 'CH04',\n",
    "'ch06': 'CH06',\n",
    "'ch07': 'CH07',\n",
    "'ch08': 'CH08',\n",
    "'ch12': 'CH12', \n",
    "'ch13': 'CH13', \n",
    "'ch14': 'CH14',\n",
    "'nivel_ed': 'NIVEL_ED',\n",
    "'estado': 'ESTADO',\n",
    "'cat_ocup': 'CAT_OCUP',\n",
    "'cat_inac': 'CAT_INAC',\n",
    "'pp3e_tot': 'PP3E_TOT', \n",
    "'pp3f_tot': 'PP3F_TOT',\n",
    "'pp04b_cod': 'PP04B_COD',\n",
    "'p21':'P21',\n",
    "'itf':'ITF',\n",
    "'ipcf': 'IPCF'\n",
    "})\n",
    "\n",
    "#Ahora uno a las 2 bases de datos individuales del 2.a\n",
    "\n",
    "sel_indiv_c = pd.concat([t0125_sel_c, t0105_sel_c], axis=0, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43fd1e0-006b-4559-a4e2-815c62ac6fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# AHORA UNON DE HOGARES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d21870-5675-40bd-a878-183206fd5077",
   "metadata": {},
   "outputs": [],
   "source": [
    "# documento de HOGARES\n",
    "#Para TIPO DE VIVIENDA\n",
    "\n",
    "#Defino el diccionario de valores que debe buscar y reemplazar\n",
    "iv1_map = {\n",
    "    'Casa': 1,     'Departamento': 2,\n",
    "    'Pieza  de inquilinato': 3,    'Pieza  de hotel/Pensión': 4,\n",
    "    'Local no construido para habitacion': 5,  'Otros': 6\n",
    "}\n",
    "\n",
    "th0105, errores = mapear_columna(th0105, 'iv1', iv1_map)\n",
    "\n",
    "#una vez recodificado transformo el tipo de dato a numerico\n",
    "th0105['iv1'] = pd.to_numeric(th0105['iv1'], errors='coerce')\n",
    "\n",
    "####################################################################################################\n",
    "#Para EN CUANTOS AMBIENTES VIVE\n",
    "\n",
    "#Aqui solo transformo el tipo de dato a numerico. La opcion errors='coerce' deja el dato como NA´s.\n",
    "th0105['iv2'] = pd.to_numeric(th0105['iv2'], errors='coerce')\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "\n",
    "#Para TIENE AGUA\n",
    "\n",
    "#Defino el diccionario de valores que debe buscar y reemplazar\n",
    "iv6_map = {\n",
    "    'Por cañeria dentro de la vivienda': 1,     'Fuera de la vivienda pero dentro del terreno': 2,    'Fuera del terreno': 3\n",
    "            }\n",
    "#Para meter los errores en una lista que vaya encontrado la transformacion y después que pueda imprimir y ver de corregirlos\n",
    "\n",
    "th0105, errores = mapear_columna(th0105, 'iv6', iv6_map)\n",
    "\n",
    "#una vez recodificado transformo el tipo de dato a numerico\n",
    "th0105['iv6'] = pd.to_numeric(th0105['iv6'], errors='coerce')\n",
    "####################################################################################################\n",
    "\n",
    "# tomare a la variable de TIENE LETRINA con una Dummies, recodificandola en 0 y 1.\n",
    "\n",
    "th0105['iv8'] = np.where(th0105['iv8']  ==  'Sí', 1, 0)\n",
    "th0105['iv8'] = np.where(th0105['iv8']  ==  'Sí', 1, 0)\n",
    "\n",
    "\n",
    "#una vez recodificado transformo el tipo de dato\n",
    "th0105['iv8'] = th0105['iv8'].astype('int64')\n",
    "\n",
    "th0105['iv8'] = th0105['iv8'].replace(0, np.nan)\n",
    "th0125['IV8'] = th0125['IV8'].replace(0, np.nan)\n",
    "\n",
    "####################################################################################################\n",
    "\n",
    "#Para COMBUSTIBLE PARA COCINAR\n",
    "\n",
    "#Defino el diccionario de valores que debe buscar y reemplazar\n",
    "ii8_map = {\n",
    "    'Gas de red': 1,     'Gas de tubo/garrafa': 2,    'Kerosene/leña/carbon': 3,    'Otro': 4\n",
    "            }\n",
    "\n",
    "th0105, errores = mapear_columna(th0105, 'ii8', ii8_map)\n",
    "\n",
    "#una vez recodificado transformo el tipo de dato a numerico\n",
    "th0105['ii8'] = pd.to_numeric(th0105['ii8'], errors='coerce')\n",
    "\n",
    "\n",
    "th0105['ii8'] = th0105['ii8'].replace(0, np.nan)\n",
    "th0125['II8'] = th0125['II8'].replace(0, np.nan)\n",
    "\n",
    "\n",
    "#th0105"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6372f5a1-ea60-4bd4-8612-7458bf4762ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecciono  las filas y columnas con la que trabajaré de cada trimestre\n",
    "\n",
    "th0105_sel_c = th0105[['CODUSU', 'nro_hogar', 'iv1', 'iv2', 'iv6', 'iv8', 'ii8','IX_Tot']].copy()\n",
    "#sel_th0105\n",
    "\n",
    "th0125_sel_c = th0125[['CODUSU','NRO_HOGAR','IV1', 'IV2', 'IV6', 'IV8', 'II8','IX_TOT']].copy()\n",
    "#sel_th0125\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f2dcdc-bc44-46bd-b709-f046d705cfa3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baf0c0a0-96d4-4286-bcb9-03b084b0559e",
   "metadata": {},
   "outputs": [],
   "source": [
    "th0105_sel_c = th0105_sel_c.rename(columns={\n",
    "'nro_hogar': 'NRO_HOGAR',\n",
    "'iv1': 'IV1',\n",
    "'iv2': 'IV2',\n",
    "'iv6': 'IV6',\n",
    "'iv8': 'IV8',\n",
    "'ii8': 'II8',\n",
    "'IX_Tot': 'IX_TOT'      \n",
    "})\n",
    "\n",
    "#Ahora uno a las 2 bases de datos individuales del 2.a\n",
    "\n",
    "sel_hogar_c = pd.concat([th0125_sel_c, th0105_sel_c], axis=0, ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258787ed-7416-4a1f-a2b9-033fe2d2b3aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ahora se va a cruzar los dataframes de individuos y hogares\n",
    "union_eph_1 = pd.merge(sel_indiv_c,sel_hogar_c, on=('CODUSU','NRO_HOGAR'), how='left')\n",
    "\n",
    "union_eph_1[['CODUSU','NRO_HOGAR','IV1', 'IV2', 'IV6', 'IV8', 'II8',\n",
    "           'CODUSU', 'NRO_HOGAR', 'REGION', 'AGLOMERADO', 'PONDERA', \n",
    "           'CH03', 'CH04', 'CH06', 'CH07', 'CH08', 'CH12', 'CH13', 'CH14', \n",
    "           'NIVEL_ED', 'ESTADO', 'CAT_OCUP', 'CAT_INAC', 'PP3E_TOT', 'PP3F_TOT', 'PP04B_COD', 'P21',\n",
    "           'ITF', 'IPCF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3191408d-20fe-4bd5-862a-81e5f199ec3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SUBO LISTADO DE POBREZA REALIZADO EN EL TP2\n",
    "eph_n_pobreza = pd.read_excel('eph_n_pobreza_x_hog.xlsx')\n",
    "\n",
    "eph_n_pobreza_1= eph_n_pobreza[['CODUSU','NRO_HOGAR','CH03','CH04','CH06','CH07','CH08','NIVEL_ED','pobre','ingreso_necesario','ad_equiv_hogar']].copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9288c4c3-87c3-4619-ab5e-dd766fe5109e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "union_eph = pd.merge(union_eph_1,eph_n_pobreza_1, on=('CODUSU','NRO_HOGAR','CH03','CH04','CH06','CH07','CH08','NIVEL_ED'), how='right')\n",
    "union_eph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11780843-f91a-423c-a207-5e97fa57e048",
   "metadata": {},
   "source": [
    "\n",
    "<h3 style=\"color: navy;\">Parte I.1</h3>\n",
    "<p> \n",
    "Cree la variable “edad2” definida como edad2 (edad al cuadrado). Presente un histograma de la variable edad en un panel A, \n",
    "y a la par una distribución de kernels para los pobres y no pobres en un panel B (esto es, son dos líneas de kernel en este segundo panel). \n",
    "Comente brevemente la distribución de edades en estos dos paneles (3-4 oraciones). '\n",
    "</p>\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27079fac-3514-4120-81e2-e144d74d451f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CRE0 EDAD_2\n",
    "union_eph['EDAD_2'] =  union_eph[\"CH06\"].fillna(0) ** 2\n",
    "\n",
    "# Configurar el gráfico\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# PANEL A: Historigrama de EDAD_2\n",
    "\n",
    "sns.histplot(union_eph['CH06'], bins=10, kde=False, ax=axs[0], color='blue')\n",
    "\n",
    "axs[0].set_title('Histograma de Edades')\n",
    "axs[0].set_xlabel('Edad')\n",
    "axs[0].set_ylabel('Frecuencia')\n",
    "\n",
    "# PANEL B: Distribución de kernels para POBRES y NO POBRES\n",
    "\n",
    "sns.kdeplot(data=union_eph[union_eph['pobre'] == 0], x='CH06', fill=True, label='No Pobres', ax=axs[1], color='green')\n",
    "sns.kdeplot(data=union_eph[union_eph['pobre'] == 1], x='CH06', fill=True, label='Pobres', ax=axs[1], color='red')\n",
    "\n",
    "axs[1].set_title('Distribución de Edades por Estado Económico')\n",
    "axs[1].set_xlabel('Edad')\n",
    "axs[1].set_ylabel('Densidad')\n",
    "axs[1].legend()\n",
    "\n",
    "# Para mostrar los gráficos\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848d09b4-e73a-4f26-9292-935d1fdcc0b6",
   "metadata": {},
   "source": [
    "<h3 style=\"color: navy;\">Parte I.2</h3>\n",
    "<p> \n",
    "Cree la variable educ definida como la cantidad de años de educación. \n",
    "Use inteligentemente las variables CH12, CH13 y CH14 para crearla. Por ejemplo, si dice que el nivel más alto de educación \n",
    "es “Secundario” (CH12), “Sí” finalizo este nivel (CH13)  y el último año que aprobó (CH14) fue “sexto”, \n",
    "entonces puede asumir que tiene  educ=12, osea 12 años de educación formal. \n",
    "\n",
    "Presente una estadística descriptiva (promedio, sd, min, p50, max) de dicha variable creada y comente\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1bb670-09f9-4ed2-9b39-27cc1ef80917",
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRESCOLAR\n",
    "union_eph.loc[(union_eph.CH12 == 1 ) & (union_eph.CH13 == 2), 'EDUC']=0\n",
    "union_eph.loc[(union_eph.CH12 == 1 ) & (union_eph.CH13 == 1), 'EDUC']=0\n",
    "\n",
    "#PRIMARIA (7 años mas)\n",
    "union_eph.loc[(union_eph.CH12 == 2) & (union_eph.CH13  == 2), 'EDUC'] = union_eph['CH14']\n",
    "union_eph.loc[(union_eph.CH12 == 2) & (union_eph.CH13  == 1), 'EDUC']= 7\n",
    "\n",
    "#EGB (9 años mas)\n",
    "union_eph.loc[(union_eph.CH12 == 3) & (union_eph.CH13  == 2), 'EDUC'] = union_eph['CH14']\n",
    "union_eph.loc[(union_eph.CH12 == 3) & (union_eph.CH13  == 1), 'EDUC']=9\n",
    "\n",
    "#SECUNDARIO (5 años mas)\n",
    "union_eph.loc[(union_eph.CH12 == 4) & (union_eph.CH13  == 2), 'EDUC'] = union_eph['CH14'] + 7\n",
    "union_eph.loc[(union_eph.CH12 == 4) & (union_eph.CH13  == 1 ), 'EDUC']=12\n",
    "\n",
    "#POLIMODAL (3 años mas)\n",
    "union_eph.loc[(union_eph.CH12 == 5) & (union_eph.CH13  == 2), 'EDUC'] = union_eph['CH14'] + 9\n",
    "union_eph.loc[(union_eph.CH12 == 5) & (union_eph.CH13 == 1), 'EDUC']=12\n",
    "\n",
    "#TERCIARIO (2 años mas)\n",
    "union_eph.loc[(union_eph.CH12 == 6) & (union_eph.CH13  == 2), 'EDUC'] = union_eph['CH14'] + 12\n",
    "union_eph.loc[(union_eph.CH12 == 6) & (union_eph.CH13 == 1), 'EDUC']=14\n",
    "\n",
    "#UNIVERSITARIO (5 años mas)\n",
    "union_eph.loc[(union_eph.CH12 == 7) & (union_eph.CH13  == 2), 'EDUC'] = union_eph['CH14'] + 12 \n",
    "union_eph.loc[(union_eph.CH12 == 7) & (union_eph.CH13 == 1), 'EDUC']=17\n",
    "\n",
    "#POSTGRADO (3 años mas)\n",
    "union_eph.loc[(union_eph.CH12 == 8) & (union_eph.CH13  == 2), 'EDUC'] = union_eph['CH14'] + 17\n",
    "union_eph.loc[(union_eph.CH12 == 8) & (union_eph.CH13 == 1), 'EDUC']=20\n",
    "\n",
    "#ESPECIAL (como primaria)\n",
    "union_eph.loc[(union_eph.CH12 == 9) & (union_eph.CH13  == 2), 'EDUC'] = union_eph['CH14'] \n",
    "union_eph.loc[(union_eph.CH12 == 9) & (union_eph.CH13 == 1), 'EDUC']=7\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "714f27ba-afa6-4ce0-aa62-c168773879cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Hago las estadísticas descriptivas\n",
    "\n",
    "stats = union_eph['EDUC'].describe()\n",
    "\n",
    "print(\"Estadísticas descriptivas de la variable EDUC:\")\n",
    "print(stats)\n",
    "\n",
    "#Veo la desviación estándar específicamente\n",
    "\n",
    "sd = union_eph['EDUC'].std()\n",
    "print(f\"\\nDesviación estándar: {sd:.2f}\")\n",
    "\n",
    "# Histograma para visualizar la distribución\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(union_eph['EDUC'], kde=True)\n",
    "\n",
    "plt.title('Distribución de Años de Educación (EDUC)')\n",
    "plt.xlabel('Años de Educación')\n",
    "plt.ylabel('Frecuencia')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# Distribución y los valores atípicos\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.boxplot(x=union_eph['EDUC'])\n",
    "\n",
    "plt.title('Boxplot de Años de Educación (EDUC)')\n",
    "plt.xlabel('Años de Educación')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de1ac512-764a-40fb-ab3a-fc56919dcbea",
   "metadata": {},
   "source": [
    "<h3 style=\"color: navy;\">Parte I.3</h3>\n",
    "<p> \n",
    "Actualice la variable ingreso_total_familiar con el total de ingresos habituales (ITF). \n",
    "Recuerde que los pesos de 2005 tienen un poder de compra distinto a los pesos de 2025 en el primer trimestre. \n",
    "<br> \n",
    "Convierta primero los ingresos de 2005 a pesos de 2025. Similar al ítem 1, presente en un panel A, \n",
    "un histograma de la variable ingreso_total_familiar y las distribuciones de kernels para pobres y no pobres en un panel B. \n",
    "<br> \n",
    "Comente brevemente la distribución de ingresos en estos dos panels (3-4 oraciones). \n",
    "<br> \n",
    "En cada panel, sume una linea vertical con la línea de la pobreza calculada en el TP2.\n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f781716b-ae2c-4770-ac9b-4debd6b7d5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Debido a la controversia sobre los datos del INDEC entre 2007-2015, utilizaremos allí el IPC Congreso\n",
    "# Fuente 1: INDEC oficial para períodos 2005-2007 y 2016-2025\n",
    "# Fuente 2: Estimaciones alternativas para 2007-2015 (IPC Congreso, consultoras privadas)\n",
    "\n",
    "# Creo los trimestrales del periodo\n",
    "periodos = []\n",
    "\n",
    "for ANIO in range(2005, 2026):\n",
    "    for trim in range(1, 5):\n",
    "        if ANIO == 2025 and trim > 1:\n",
    "            break\n",
    "        periodos.append(f\"{ANIO} Q{trim}\")\n",
    "\n",
    "# Estos son los valores\n",
    "ipc_valores = [\n",
    "    # 2005\n",
    "    104.2, 107.8, 111.0, 114.8,\n",
    "    # 2006\n",
    "    118.9, 123.5, 127.2, 131.1,\n",
    "    # 2007\n",
    "    135.6, 141.2, 147.3, 153.8,\n",
    "    # 2008\n",
    "    162.5, 172.3, 181.4, 188.6,\n",
    "    # 2009\n",
    "    196.2, 203.5, 209.8, 216.3,\n",
    "    # 2010\n",
    "    224.8, 235.2, 246.3, 257.5,\n",
    "    # 2011\n",
    "    270.4, 285.6, 300.2, 315.8,\n",
    "    # 2012\n",
    "    332.1, 350.4, 368.2, 386.5,\n",
    "    # 2013\n",
    "    406.8, 430.2, 455.0, 481.3,\n",
    "    # 2014\n",
    "    520.6, 567.5, 615.8, 665.0,\n",
    "    # 2015\n",
    "    720.5, 782.3, 848.8, 925.2,\n",
    "    # 2016\n",
    "    1020.8, 1122.9, 1213.5, 1298.6,\n",
    "    # 2017\n",
    "    1388.5, 1456.9, 1518.5, 1585.8,\n",
    "    # 2018\n",
    "    1686.2, 1812.7, 1978.6, 2178.5,\n",
    "    # 2019\n",
    "    2405.3, 2685.9, 2954.5, 3294.1,\n",
    "    # 2020\n",
    "    3623.5, 3877.2, 4187.4, 4556.3,\n",
    "    # 2021\n",
    "    5012.0, 5513.2, 6009.4, 6550.2,\n",
    "    # 2022\n",
    "    7205.2, 8145.9, 9452.2, 11247.1,\n",
    "    # 2023\n",
    "    13946.4, 17851.4, 23206.8, 32025.4,\n",
    "    # 2024\n",
    "    41633.0, 49959.6, 57453.5, 63198.9,\n",
    "    # 2025\n",
    "    67642.8\n",
    "]\n",
    "\n",
    "# Cre0 el DataFrame con el diccionario\n",
    "df = pd.DataFrame({\n",
    "    'Periodo': periodos,\n",
    "    'IPC': ipc_valores\n",
    "})\n",
    "\n",
    "# Calculo la inflación acumulada desde el 2005 hasta el 2025\n",
    "inflacion_acumulada = (df['IPC'].iloc[-1] / df['IPC'].iloc[0] - 1) * 100\n",
    "\n",
    "\n",
    "# El gráfico de la evolución del IPC\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "plt.plot(df['Periodo'][::4], df['IPC'][::4], marker='o')  # Muestra un punto por año, para mejorar la visualización\n",
    "\n",
    "plt.title('Evolución del IPC en Argentina (2005-2025)')\n",
    "plt.xlabel('Período')\n",
    "plt.ylabel('IPC (Base 100 = Q4 2004)')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "\n",
    "# Mostrar el resultado\n",
    "print(f\"Inflación acumulada desde 1er Trim 2005 hasta el 1er Trim 2025: {inflacion_acumulada:.2f}%\")\n",
    "print(f\"Factor de actualización: {df['IPC'].iloc[-1] / df['IPC'].iloc[0]:.2f}\")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ac9994-5d7b-42c7-bb2e-0a6f103a1ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creo una columna nueva,ITF_05_25, de ITF a valores de 2025\n",
    "\n",
    "union_eph.loc[(union_eph.ANIO == 2005 ) , 'ITF_05_25']=union_eph[\"ITF\"].fillna(0)*(1+649.16)\n",
    "union_eph.loc[(union_eph.ANIO == 2025 ) , 'ITF_05_25']=union_eph[\"ITF\"].fillna(0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c1c7a2-7a3a-41b9-8dc3-f6d09555e1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_texto = \"\"\"\n",
    "<p> \n",
    "En el Historigrama la mayor frecuencia se encuentra alrededor de los $400.000 de ITF. Siendo muy cercana \n",
    "a la línea verde representa la Canasta Básica Total, que se ubica en 365.177 miles.\n",
    "<br>\n",
    "En el grafico de densidad se visualiza nuevamente la gran relevancia de la pobreza en los mas jovenes y adicionalmente \n",
    "se puede observar la mayor amplitud en los niveles de ingresos de los no pobres en relacion la mayor frecuencia en los \n",
    "niveles de ingreso menores.  \n",
    "</p>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022e9a64-3e92-462e-a63c-c85dfa615a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "#Segun nos informaba el TP2 en el punto 7, el limite de pobreza era\n",
    "cbt_pob_25=365.177\n",
    "\n",
    "# Filtro y creo una copia para poder reducir optimizar la visualizacion en el grafico\n",
    "union_itf = union_eph[(union_eph['pobre'].isin([0, 1])) & (union_eph['ITF_05_25'] != 0)].copy()\n",
    "union_itf['ITF_05_25_2'] = union_itf['ITF_05_25'] / 1000\n",
    "\n",
    "\n",
    "# PANEL A: Historigrama de Ingreso Total Familiar ajustados al 2025 \n",
    "\n",
    "sns.histplot(data=union_itf['ITF_05_25_2'], bins=20, kde=False, ax=axs[0], color='blue')\n",
    "axs[0].axvline(365.177, color='green', linestyle='--', label=f'Canasta Basica Total(Miles): {cbt_pob_25}')\n",
    "\n",
    "axs[0].set_title('Histograma Ingreso Total Familiar - ITF (en Miles)')\n",
    "axs[0].set_xlabel('ITF ajustados al 2025 (en miles)')\n",
    "axs[0].set_ylabel('Frecuencia')\n",
    "axs[0].legend()\n",
    "\n",
    "# PANEL B: Distribución de kernels para POBRES y NO POBRES\n",
    "\n",
    "sns.kdeplot(data=union_itf[union_itf['pobre'] == 0], x='ITF_05_25_2', fill=True, label='No Pobres', ax=axs[1], color='green')\n",
    "sns.kdeplot(data=union_itf[union_itf['pobre'] == 1], x='ITF_05_25_2', fill=True, label='Pobres', ax=axs[1], color='red')\n",
    "\n",
    "plt.axvline(cbt_pob_25, color='violet', linestyle='--', label=f'Canasta Basica Total(Miles): {cbt_pob_25}')\n",
    "\n",
    "axs[1].set_title('Distribución de Ingreso Total Familiar')\n",
    "axs[1].set_xlabel('ITF ajustados al 2025(en miles)')\n",
    "axs[1].set_ylabel('Densidad')\n",
    "axs[1].legend()\n",
    "\n",
    "# Para mostrar los gráficos\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec709e56-789c-434f-bc56-c884ea5a3698",
   "metadata": {},
   "source": [
    "<h3 style=\"color: navy;\">Parte I.4</h3>\n",
    "<p> \n",
    "Para el jefe del hogar, cree la variable horastrab como el total de horas trabajadas \n",
    "como la suma de las horas en la ocupación principal y otras ocupaciones (PP3E_TOT + PP3F_TOT). \n",
    "<br> \n",
    "Presente una estadística descriptiva (promedio, sd, min, p50, max) de dicha variable creada y comente</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c662e70-991d-4fbf-b86a-e2cf7f2d05d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "html_texto = \"\"\"\n",
    "<p> \n",
    "El gráfico nos habla de que la mayoría de los jefes de hogar trabajan \n",
    "entre 20 y 80 horas por semana, con un pico alrededor de las 50 horas. <br>\n",
    "Como muestra de ello, vemos la media en 42,19 (muy cerca de la mediana de 40) y un desvio standart cercano a la 20 hs\n",
    "</p>\n",
    "\"\"\"\n",
    "\n",
    "display(HTML(html_texto))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c49d09-c86c-4790-a057-50876b73c5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Creo una nueva columna con la suma de horas semanales dedicadas a las actividades principales y a las secundarias, \n",
    "# donde conjuntamente no superen las 120hs (16hs diarias) y los ceros los vuelvo nulls para no distorcionar lo informado.\n",
    "\n",
    "union_eph[\"horastrab\"] = np.where((union_eph[\"PP3E_TOT\"].fillna(0) + union_eph[\"PP3F_TOT\"].fillna(0))>112,112,(union_eph[\"PP3E_TOT\"].fillna(0) + union_eph[\"PP3F_TOT\"].fillna(0)))\n",
    "union_eph[\"horastrab\"] = union_eph[\"horastrab\"].replace(0, np.nan)\n",
    "\n",
    "eph_jefehog = union_eph.loc[(union_eph.CH03 == 1 )]\n",
    "\n",
    "# Las estadísticas descriptivas\n",
    "stats = eph_jefehog[\"horastrab\"].describe()\n",
    "print(\"Estadísticas descriptivas de la variable 'horastrab' de los Jef@s de hogares:\")\n",
    "print(stats)\n",
    "\n",
    "# La desviación estándar explícitamente\n",
    "sd = eph_jefehog[\"horastrab\"].std()\n",
    "print(f\"\\nDesviación estándar: {sd:.2f}\")\n",
    "\n",
    "# El HISTOGRAMA\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "sns.histplot(data=eph_jefehog, x=\"horastrab\", bins=10, kde=True, color='steelblue')\n",
    "\n",
    "plt.axvline(eph_jefehog[\"horastrab\"].mean(), color='red', linestyle='--', label=f'Media: {eph_jefehog[\"horastrab\"].mean():.2f}')\n",
    "plt.axvline(eph_jefehog[\"horastrab\"].median(), color='green', linestyle='--', label=f'Mediana: {eph_jefehog[\"horastrab\"].median():.2f}')\n",
    "\n",
    "plt.title('Distribución de Horas Trabajadas Semanales de los Jef@s de Hogares', fontsize=15)\n",
    "plt.xlabel('Horas trabajadas', fontsize=12)\n",
    "plt.ylabel('Frecuencia', fontsize=12)\n",
    "\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5c7be3-ae59-4e4c-9f6e-c612594ec373",
   "metadata": {},
   "source": [
    "<h3 style=\"color: navy;\">Parte I.5</h3>\n",
    "<p> \n",
    "¿Cuál es el tamaño de la de la base de datos para su región con las variables originales unificadas? \n",
    "Para ello complete la tabla 1 que se le diseña abajo y comente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b56b2e7c-e35d-4cc5-a716-1b54f2adbb00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Me quedo solo con la región 40, NOA, que era nuestra region elegida.\n",
    "df_region40 = union_eph[union_eph['REGION'] == 40]\n",
    "\n",
    "# Crear el cuadro solicitado\n",
    "# 1. Cantidad de observaciones\n",
    "obs_2005 = len(df_region40[df_region40['ANIO'] == 2005])\n",
    "obs_2025 = len(df_region40[df_region40['ANIO'] == 2025])\n",
    "obs_total = obs_2005 + obs_2025\n",
    "\n",
    "# 2. Cantidad de observaciones con NAs de \"Pobre\"\n",
    "nas_2005 = df_region40[(df_region40['ANIO'] == 2005) & (df_region40['pobre'].isna())].shape[0]\n",
    "nas_2025 = df_region40[(df_region40['ANIO'] == 2025) & (df_region40['pobre'].isna())].shape[0]\n",
    "nas_total = nas_2005 + nas_2025\n",
    "\n",
    "# 3. Cantidad de Pobres (pobre=1)\n",
    "pobres_2005 = df_region40[(df_region40['ANIO'] == 2005) & (df_region40['pobre'] == 1)].shape[0]\n",
    "pobres_2025 = df_region40[(df_region40['ANIO'] == 2025) & (df_region40['pobre'] == 1)].shape[0]\n",
    "pobres_total = pobres_2005 + pobres_2025\n",
    "\n",
    "# 4. Cantidad de No Pobres (pobre=0)\n",
    "no_pobres_2005 = df_region40[(df_region40['ANIO'] == 2005) & (df_region40['pobre'] == 0)].shape[0]\n",
    "no_pobres_2025 = df_region40[(df_region40['ANIO'] == 2025) & (df_region40['pobre'] == 0)].shape[0]\n",
    "no_pobres_total = no_pobres_2005 + no_pobres_2025\n",
    "\n",
    "# Los resultados\n",
    "resultados = pd.DataFrame({\n",
    "    '2005': [obs_2005, nas_2005, pobres_2005, no_pobres_2005,'28','22'],\n",
    "    '2025': [obs_2025, nas_2025, pobres_2025, no_pobres_2025,'28','15'],\n",
    "    'Total': [obs_total, nas_total, pobres_total, no_pobres_total,'28','22']\n",
    "}, index=['Cantidad observaciones', 'Cant de observ con NAs en la vble \"Pobre\"', \n",
    "          'Cantidad de Pobres', 'Cantidad de No Pobres', 'Variables Orig Homogeneizadas','Cant Variables Orig Limpiadas'\n",
    "         ])\n",
    "\n",
    "print(\"\\nCuadro de resultados para la región 40:\")\n",
    "print(resultados)\n",
    "\n",
    "# Para ver que los números sean consistentes\n",
    "print(\"\\nVerificación de consistencia:\")\n",
    "print(f\"Suma de pobres, no pobres y NAs en 2005: {pobres_2005 + no_pobres_2005 + nas_2005} (debe ser igual a {obs_2005})\")\n",
    "print(f\"Suma de pobres, no pobres y NAs en 2025: {pobres_2025 + no_pobres_2025 + nas_2025} (debe ser igual a {obs_2025})\")\n",
    "\n",
    "# Porcentajes de pobreza (excluyendo NAs)\n",
    "porc_pobres_2005 = pobres_2005 / (pobres_2005 + no_pobres_2005) * 100 if (pobres_2005 + no_pobres_2005) > 0 else 0\n",
    "porc_pobres_2025 = pobres_2025 / (pobres_2025 + no_pobres_2025) * 100 if (pobres_2025 + no_pobres_2025) > 0 else 0\n",
    "porc_pobres_total = pobres_total / (pobres_total + no_pobres_total) * 100 if (pobres_total + no_pobres_total) > 0 else 0\n",
    "\n",
    "print(\"\\nPorcentajes de pobreza (excluyendo NAs):\")\n",
    "print(f\"Porcentaje de pobres en 2005: {porc_pobres_2005:.2f}%\")\n",
    "print(f\"Porcentaje de pobres en 2025: {porc_pobres_2025:.2f}%\")\n",
    "print(f\"Porcentaje de pobres total: {porc_pobres_total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab6ed1b-cc91-4225-9053-e2af70cfb38c",
   "metadata": {},
   "source": [
    "<span style=\"color:#1e90ff\">Parte II: Métodos No Supervisados</span>\n",
    "\n",
    "Esta parte del trabajo práctico tiene como objetivo que realicen un análisis visual de los datos utilizando las herramientas vistas en clase. En esta parte, solo necesita utilizar las variables: edad, edad2, educ, ingreso_total_familiar (ITF), el número de miembros en el hogar (2005 = IX_TOT, 2025 = IX_Tot) y horastrab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b697f940-bac2-4b00-bbd8-3263f3dd5ac4",
   "metadata": {},
   "source": [
    "1. Realice una matriz de correlaciones con estos seis predictores para su región y comente los resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd8513f-c50c-44c5-8a03-ffee4616f416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agrego una condicion a la variable horas trabajadas para distinguir entre los valores con 0 y los nan que puedo eliminar en la variable educacion\n",
    "condicion = union_eph['ESTADO'].isin([2, 3, 4])\n",
    "union_eph.loc[condicion, 'horastrab'] = 0\n",
    "#Armo la base de datos\n",
    "var_Mns = ['IX_TOT','EDAD_2','ITF_05_25','horastrab','EDUC','CH06']\n",
    "MnS_Data = union_eph[var_Mns]\n",
    "MnS_Data.columns = ['Miembros_Hogar', 'Edad_Cuadrado', 'Ingreso', 'HsTrabajadas', 'AniosEducacion', 'Edad']\n",
    "MnS_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260976ff-0b50-4080-841a-32681b12ae4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "upp_mat = np.triu(MnS_Data.corr())\n",
    "plt.figure(figsize=(13, 12))\n",
    "upp_mat = np.triu(MnS_Data.corr(),k=1)\n",
    "sns.heatmap(MnS_Data.corr(), vmin=-1, vmax=+1, annot=True, cmap=\"coolwarm\", fmt=\".2f\",linewidths=1, mask = upp_mat)\n",
    "plt.text(x=4.5,  y=1,  s='Matriz de correlaciones\\n',horizontalalignment='center',verticalalignment='center', fontsize=20,fontweight='bold')\n",
    "plt.gca().grid(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6249b6f-e0b8-462e-bb3e-5e0818b89f3e",
   "metadata": {},
   "source": [
    "A. PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a1e3993-de4f-4969-9f4c-092a04f77f58",
   "metadata": {},
   "source": [
    "2. PCA con ingreso: Apliquen PCA a las seis variables seleccionadas para esta parte. Recuerde primero estandarizar las variables como vimos en la tutorial. En un gráfico de dispersión muestren los índices (scores) calculados del primer y segundo componente de PCA y comente los resultados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dff909e6-2bbf-412e-a9d8-17133dc3d8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Para esta parte me quedo solo con los valores que se pudieron recolectar. Aquellos que se encuentran NAN no se usaran para el analis.\n",
    "MnS_Data = MnS_Data.dropna()\n",
    "MnS_Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd597c34-5e13-4b93-9fcb-653ebfdd282c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Estandarizamos los datos\n",
    "scaler = StandardScaler(with_std=True, with_mean=True) \n",
    "# Aplicamos fit_transform al DataFrame\n",
    "Pca_data = pd.DataFrame(scaler.fit_transform(MnS_Data), columns=MnS_Data.columns)\n",
    "Pca_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "905afa01-afa1-49ae-bc36-49ff94f48d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "eph_pca = pca.fit_transform(Pca_data)\n",
    "scores = eph_pca\n",
    "eph_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c94ff5c-c519-40bf-b5d3-f7cbb94ea4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loading_vectors = pca.components_ # cada fila corresponde a un CP y cada columna, a una variable\n",
    "print(\"Loadings:\\n\", pca.components_)\n",
    "print(\"Loadings del CP1:\\n\",pca.components_[0]) \n",
    "pca.components_[0,0] #loadings del CP1 variable 1, phi(1,1) en ecuacion 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2474357-c369-499f-9c35-d449ce5e2d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobamos la condicion de los loadings del CP1\n",
    "(-0.34173248)**2+(0.57770448)**2+(0.09468439)**2+( 0.21960168)**2+(0.33678438)**2+(0.61551824)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09038937-fa3e-479d-9f26-03ce743790bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "i, j = 0, 1 # Componentes\n",
    "fig, (ax_scores, ax_ponderadores) = plt.subplots(1, 2, figsize=(10, 5)) # 1 fila, 2 columnas\n",
    "# ---\n",
    "## Panel A. Score 1 y 2\n",
    "ax_scores.scatter(scores[:,0], scores[:,1], s=30, alpha=0.7) # graficamos los valores de los CP1 y CP2\n",
    "ax_scores.set_xlabel('Componente Principal %d' % (i+1))\n",
    "ax_scores.set_ylabel('Componente Principal %d' % (j+1))\n",
    "ax_scores.set_title('A. Score 1 y 2')\n",
    "# Líneas punteadas en los ejes\n",
    "ax_scores.axhline(0, color='gray', linestyle='--', linewidth=0.8) # Eje horizontal en y=0\n",
    "ax_scores.axvline(0, color='gray', linestyle='--', linewidth=0.8) # Eje vertical en x=0\n",
    "# ---\n",
    "## Panel B. Ponderadores\n",
    "# Líneas punteadas en los ejes\n",
    "ax_ponderadores.axhline(0, color='gray', linestyle='--', linewidth=0.8) # Eje horizontal en y=0\n",
    "ax_ponderadores.axvline(0, color='gray', linestyle='--', linewidth=0.8) # Eje vertical en x=0\n",
    "# ponderadores\n",
    "for k in range(pca.components_.shape[1]): # loop que itera por la cantidad de features\n",
    "    ax_ponderadores.arrow(0, 0, pca.components_[i,k], pca.components_[j,k], color ='red', head_width=0.03) # flecha desde el origen (0) a las coordenadas\n",
    "    ax_ponderadores.text(pca.components_[i,k]+0.03, pca.components_[j,k], Pca_data.columns[k], color ='red',fontsize=7.3) # al final de cada flecha, nombre de la variable\n",
    "ax_ponderadores.set_xlabel('Ponderador de CP %d' % (i+1))\n",
    "ax_ponderadores.set_ylabel('Ponderador de CP %d' % (j+1))\n",
    "ax_ponderadores.set_title('B. Ponderadores')\n",
    "ax_ponderadores.set_xlim(-1, 1)\n",
    "ax_ponderadores.set_ylim(-1, 1)\n",
    "plt.tight_layout() # Ajusta los subplots para que no se superpongan\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f62e126b-f00b-4cc0-be74-6a4dfd65d0c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef0e7766-f160-49b0-91b7-660eb7d60090",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comprobamos que la suma de 1\n",
    "0.38525844  +0.21450067  +0.16744034 +0.13014826 +0.09977114+0.00288115"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e70316c7-eb72-4b06-81e7-e1d421944ae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Armamos el gráfico\n",
    "plt.close('all')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 4))\n",
    "ticks = np.arange(pca.n_components_) + 1\n",
    "\n",
    "# Título general de la figura\n",
    "fig.suptitle(\"Gráfico de varianza explicada\", fontsize=14, fontweight=\"bold\", y=1.02)\n",
    "\n",
    "# Subplot 1: varianza explicada por componente\n",
    "ax = axes[0]\n",
    "ax.plot(ticks, pca.explained_variance_ratio_, marker='o')\n",
    "ax.set_xlabel('Nro. de Componente Principal ($M$)')\n",
    "ax.set_ylabel('Prop. de la varianza explicada')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_xticks(ticks)\n",
    "\n",
    "# Subplot 2: varianza explicada acumulada\n",
    "ax = axes[1]\n",
    "ax.plot(ticks, pca.explained_variance_ratio_.cumsum(), marker='o', color=\"orange\")\n",
    "ax.set_xlabel('Nro. de Componente Principal ($M$)')\n",
    "ax.set_ylabel('Suma acumulada de la varianza explicada')\n",
    "ax.set_ylim([0, 1])\n",
    "ax.set_xticks(ticks)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58edb5d9-03bd-411a-b4c5-46cd20451a82",
   "metadata": {},
   "source": [
    "B. Cluster"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc39e83-0b03-43a8-9690-81d1112ba983",
   "metadata": {},
   "source": [
    "5.  Cluster k-medias: "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5ca2a8-858a-4b5c-9582-bec99f6c5efb",
   "metadata": {},
   "source": [
    "a.   Corran el algoritmo con k=2, k=4 y k=10 usando n_init = 20, y grafiquen los resultados usando edad e ingreso familiar. Interprétenlos ¿Puede el algoritmo con k=2 separar correctamente a las personas pobres y no pobres en su región?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797bc853-cb18-4068-80ff-c38e24088007",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = MnS_Data[['Edad', 'Ingreso']].dropna()  # eliminamos filas con nulos si las hubiera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d104bc-ed01-4121-96cb-65031b159329",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los distintos k\n",
    "ks = [2, 4, 10]\n",
    "modelos = {}\n",
    "\n",
    "for k in ks:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=20, random_state=42)\n",
    "    X[f'cluster_{k}'] = kmeans.fit_predict(X[['Edad', 'Ingreso']])\n",
    "    modelos[k] = kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2828569a-d8d1-4a20-a1c7-f397899f48a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "for i, k in enumerate(ks):\n",
    "    ax = axes[i]\n",
    "    ax.scatter(X['Edad'], X['Ingreso'], c=X[f'cluster_{k}'], cmap='viridis', s=40)\n",
    "    ax.set_title(f'K-means con k={k}')\n",
    "    ax.set_xlabel('Edad')\n",
    "    ax.set_ylabel('Ingreso familiar')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac141d69-f64b-4a4f-9a82-7a6638181541",
   "metadata": {},
   "source": [
    "b.\tGrafique alguna medida de disimilitud para k=1 hasta k=10. Usando la inspección visual de Elbow ¿cuál sería el número óptimo de clusters en su región? ¿Dicha cantidad de grupos nos ayudaría a distinguir entre pobres y no pobres o entre distintas clases socioeconómicas? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0656462e-cfb0-4c5d-8425-274184c27ef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = MnS_Data[['Edad', 'Ingreso']].dropna()\n",
    "\n",
    "inertias = []\n",
    "K = range(1, 11)\n",
    "\n",
    "for k in K:\n",
    "    km = KMeans(n_clusters=k, n_init=20, random_state=42)\n",
    "    km.fit(X)\n",
    "    inertias.append(km.inertia_)\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(K, inertias, marker='o')\n",
    "plt.title('Método de Elbow')\n",
    "plt.xlabel('Número de clusters (k)')\n",
    "plt.ylabel('Inercia o suma de cuadrados intra-cluster')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72edf467-d96d-4d94-9eaf-50347daa944c",
   "metadata": {},
   "source": [
    "6.\tCluster jerárquico: Utilizando las variables mencionadas arriba, realicen un análisis de clustering jerárquico. Generen un dendograma y expliquen brevemente qué es un dendograma."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3cb56a-dfd7-41c8-bbd9-7aa77ae46f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecciono las variables del análisis\n",
    "X = MnS_Data[['Edad', 'Ingreso']].dropna()\n",
    "\n",
    "# Calculo la matriz de ligamiento \n",
    "Z = linkage(X, method='ward')\n",
    "\n",
    "# Genero el dendrograma\n",
    "plt.figure(figsize=(12, 6))\n",
    "dendrogram(Z, truncate_mode='lastp', p=30, leaf_rotation=90, leaf_font_size=10)\n",
    "plt.title('Dendrograma - Clustering jerárquico')\n",
    "plt.xlabel('Observaciones agrupadas')\n",
    "plt.ylabel('Distancia o disimilitud')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
